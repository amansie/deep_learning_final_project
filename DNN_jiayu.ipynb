{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-jiayu'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test from .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load all data into cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input\n",
    "input_train = []\n",
    "with open('input_train.csv') as csvfile: \n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader: \n",
    "        input_train.append(row) \n",
    "input_train = np.array(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18542, 1421)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_train.shape)\n",
    "type(input_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = []\n",
    "with open('input_test.csv') as csvfile: \n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader: \n",
    "        input_test.append(row)\n",
    "input_test = np.array(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4636, 1421)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_test.shape)\n",
    "type(input_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load output\n",
    "output_train = []\n",
    "with open('output_train-1.csv') as csvfile: \n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader: \n",
    "        output_train.append(row)     \n",
    "output_train = np.array(output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18542, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_train.shape)\n",
    "type(output_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = []\n",
    "with open('output_test-1.csv') as csvfile: \n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader: \n",
    "        output_test.append(row)  \n",
    "output_test = np.array(output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4636, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_test.shape)\n",
    "type(output_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paramter space for random search\n",
    "lr_range = [1e-2, 1e-3, 1e-4]\n",
    "l1_range = [1e-5, 1e-7, 1e-9, 1e-11]\n",
    "l2_range = [1e-5, 1e-7, 1e-9, 1e-11]\n",
    "width_range = [64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all possible combination = 4*4*3*2 = 96\n",
    "comb_list = []\n",
    "for a in lr_range: \n",
    "    for b in l1_range: \n",
    "        for c in l2_range: \n",
    "            for d in width_range: \n",
    "                temp = [a, b, c, d]\n",
    "                comb_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 1e-05, 1e-05, 64]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random NAS on a single target gene\n",
    "def DnnRandomSearch(lr, l1, l2, width, x_train, y_train, x_test, y_test): \n",
    "    model = tf.keras.Sequential([\n",
    "        # input layer\n",
    "        tf.keras.layers.Dense(width, activation='relu', input_shape=(1421,), \n",
    "                             kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1, l2=l2)),\n",
    "\n",
    "        #hidden layers\n",
    "        tf.keras.layers.Dense(width, activation='relu', \n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1, l2=l2)),\n",
    "        tf.keras.layers.Dense(width, activation='relu', \n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1, l2=l2)),\n",
    "\n",
    "        # output layer\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = sgd,\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = ['mse']\n",
    "    )\n",
    "    \n",
    "    History = model.fit(\n",
    "        verbose = 0,\n",
    "        x = x_train,\n",
    "        y = y_train,\n",
    "        epochs = 30, \n",
    "        batch_size = 32, \n",
    "    #     callbacks = callbacks, \n",
    "        validation_data = (x_test, y_test)\n",
    "    )\n",
    "    \n",
    "    del model\n",
    "    return [History.history['val_mse'][-1], History.history['val_loss'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 random searches completed, 78.385751 seconds passed, 95 more searches need to be done\n",
      "6 random searches completed, 478.091264 seconds passed, 90 more searches need to be done\n",
      "11 random searches completed, 875.039357 seconds passed, 85 more searches need to be done\n",
      "16 random searches completed, 1273.391958 seconds passed, 80 more searches need to be done\n",
      "21 random searches completed, 1673.381538 seconds passed, 75 more searches need to be done\n",
      "26 random searches completed, 2071.751407 seconds passed, 70 more searches need to be done\n",
      "31 random searches completed, 2469.745740 seconds passed, 65 more searches need to be done\n",
      "36 random searches completed, 2869.361582 seconds passed, 60 more searches need to be done\n",
      "41 random searches completed, 3268.328574 seconds passed, 55 more searches need to be done\n",
      "46 random searches completed, 3667.725464 seconds passed, 50 more searches need to be done\n",
      "51 random searches completed, 4066.543518 seconds passed, 45 more searches need to be done\n",
      "56 random searches completed, 4465.478220 seconds passed, 40 more searches need to be done\n",
      "61 random searches completed, 4864.101910 seconds passed, 35 more searches need to be done\n",
      "66 random searches completed, 5257.601596 seconds passed, 30 more searches need to be done\n",
      "71 random searches completed, 5650.519469 seconds passed, 25 more searches need to be done\n",
      "76 random searches completed, 6045.751907 seconds passed, 20 more searches need to be done\n",
      "81 random searches completed, 6438.745106 seconds passed, 15 more searches need to be done\n",
      "86 random searches completed, 6834.002418 seconds passed, 10 more searches need to be done\n",
      "91 random searches completed, 7226.960641 seconds passed, 5 more searches need to be done\n",
      "96 random searches completed, 7622.618516 seconds passed, 0 more searches need to be done\n"
     ]
    }
   ],
   "source": [
    "# run random search and record results \n",
    "import time\n",
    "VAL_MSE_RAND = []\n",
    "VAL_LOSS_RAND = []\n",
    "target_gene_train = output_train[:, 2]\n",
    "target_gene_test = output_test[:, 2]\n",
    "start_time = time.time()\n",
    "for count, i in enumerate(comb_list): \n",
    "    lr, l1, l2, width = i[0], i[1], i[2], i[3]\n",
    "    temp = DnnRandomSearch(lr, l1, l2, width, input_train, target_gene_train, \n",
    "                                                input_test, target_gene_test)\n",
    "    VAL_MSE_RAND.append(temp[0])\n",
    "    VAL_LOSS_RAND.append(temp[1])\n",
    "    current_time = time.time()\n",
    "    if count % 5 == 0: \n",
    "        print('%d random searches completed, %f seconds passed, %d more searches need to be done' \n",
    "             %(count+1, current_time - start_time, len(comb_list) - count - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('val_mse_rand.txt', VAL_MSE_RAND)\n",
    "np.savetxt('val_loss_rand.txt', VAL_LOSS_RAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('comb_list.txt', comb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3]),)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(VAL_MSE_RAND==np.min(VAL_MSE_RAND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 1e-05, 1e-07, 128]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7622 / 60 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for 10 different genes \n",
    "def DNN_train(output_gene_train, output_gene_test):\n",
    "    model = tf.keras.Sequential([\n",
    "        # input layer\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(1421,), \n",
    "                             kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-7)),\n",
    "\n",
    "        #hidden layers\n",
    "        tf.keras.layers.Dense(128, activation='relu', \n",
    "                             kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-7)),\n",
    "        tf.keras.layers.Dense(128, activation='relu', \n",
    "                             kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-7)),\n",
    "\n",
    "        # output layer\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    sgd = optimizers.SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = sgd,\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = ['mse']\n",
    "    )\n",
    "\n",
    "    History = model.fit(\n",
    "        x = input_train,\n",
    "        y = output_gene_train,\n",
    "        epochs = 30, \n",
    "        batch_size = 32, \n",
    "    #     callbacks = callbacks, \n",
    "        validation_data = (input_test, output_gene_test)\n",
    "    )\n",
    "    \n",
    "    del model\n",
    "    return [History.history['val_mse'][-1], History.history['val_loss'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 177us/sample - loss: 0.0811 - mse: 8.3834e-06 - val_loss: 0.0805 - val_mse: 7.9696e-06\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0799 - mse: 8.2379e-06 - val_loss: 0.0793 - val_mse: 7.9381e-06\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0787 - mse: 8.2356e-06 - val_loss: 0.0781 - val_mse: 8.0693e-06\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0775 - mse: 8.2352e-06 - val_loss: 0.0769 - val_mse: 8.1533e-06\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0763 - mse: 8.2411e-06 - val_loss: 0.0757 - val_mse: 7.9485e-06\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 152us/sample - loss: 0.0751 - mse: 8.2528e-06 - val_loss: 0.0745 - val_mse: 7.9653e-06\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0739 - mse: 8.2594e-06 - val_loss: 0.0733 - val_mse: 8.0123e-06\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0727 - mse: 8.2756e-06 - val_loss: 0.0721 - val_mse: 8.2192e-06\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0716 - mse: 8.2887e-06 - val_loss: 0.0710 - val_mse: 8.0705e-06\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0704 - mse: 8.2937e-06 - val_loss: 0.0699 - val_mse: 8.0323e-06\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0693 - mse: 8.3109e-06 - val_loss: 0.0687 - val_mse: 8.2175e-06\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0682 - mse: 8.3324e-06 - val_loss: 0.0676 - val_mse: 8.0462e-06\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0671 - mse: 8.3498e-06 - val_loss: 0.0665 - val_mse: 8.3154e-06\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0659 - mse: 8.3713e-06 - val_loss: 0.0654 - val_mse: 8.4466e-06\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0649 - mse: 8.3598e-06 - val_loss: 0.0643 - val_mse: 8.1130e-06\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0638 - mse: 8.3767e-06 - val_loss: 0.0632 - val_mse: 8.1128e-06\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0627 - mse: 8.3888e-06 - val_loss: 0.0622 - val_mse: 8.1198e-06\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0617 - mse: 8.3985e-06 - val_loss: 0.0611 - val_mse: 8.2814e-06\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0606 - mse: 8.4218e-06 - val_loss: 0.0601 - val_mse: 8.1941e-06\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0596 - mse: 8.4209e-06 - val_loss: 0.0591 - val_mse: 8.1550e-06\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0585 - mse: 8.4449e-06 - val_loss: 0.0580 - val_mse: 8.2557e-06\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0575 - mse: 8.4466e-06 - val_loss: 0.0570 - val_mse: 8.3376e-06\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0565 - mse: 8.4627e-06 - val_loss: 0.0560 - val_mse: 8.1890e-06\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0555 - mse: 8.4908e-06 - val_loss: 0.0550 - val_mse: 8.2399e-06\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0546 - mse: 8.4852e-06 - val_loss: 0.0541 - val_mse: 8.2134e-06\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 152us/sample - loss: 0.0536 - mse: 8.4867e-06 - val_loss: 0.0531 - val_mse: 8.2439e-06\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0526 - mse: 8.5153e-06 - val_loss: 0.0521 - val_mse: 8.2615e-06\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 167us/sample - loss: 0.0517 - mse: 8.5199e-06 - val_loss: 0.0512 - val_mse: 8.2611e-06\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0507 - mse: 8.5261e-06 - val_loss: 0.0503 - val_mse: 8.2928e-06\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0498 - mse: 8.5429e-06 - val_loss: 0.0493 - val_mse: 8.2792e-06\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 174us/sample - loss: 0.0812 - mse: 2.2439e-07 - val_loss: 0.0806 - val_mse: 2.2550e-07\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0800 - mse: 1.9919e-07 - val_loss: 0.0794 - val_mse: 2.2166e-07\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0788 - mse: 1.9433e-07 - val_loss: 0.0782 - val_mse: 2.1260e-07\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0776 - mse: 1.9202e-07 - val_loss: 0.0769 - val_mse: 2.1156e-07\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0763 - mse: 1.9151e-07 - val_loss: 0.0758 - val_mse: 2.1275e-07\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0752 - mse: 1.9118e-07 - val_loss: 0.0746 - val_mse: 2.1111e-07\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0740 - mse: 1.9087e-07 - val_loss: 0.0734 - val_mse: 2.1067e-07\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0728 - mse: 1.9067e-07 - val_loss: 0.0722 - val_mse: 2.1003e-07\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0717 - mse: 1.9038e-07 - val_loss: 0.0711 - val_mse: 2.1128e-07\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0705 - mse: 1.9080e-07 - val_loss: 0.0699 - val_mse: 2.1559e-07\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0694 - mse: 1.9093e-07 - val_loss: 0.0688 - val_mse: 2.1527e-07\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0682 - mse: 1.9067e-07 - val_loss: 0.0677 - val_mse: 2.2297e-07\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0671 - mse: 1.9144e-07 - val_loss: 0.0666 - val_mse: 2.1199e-07\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0660 - mse: 1.9163e-07 - val_loss: 0.0655 - val_mse: 2.1220e-07\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0649 - mse: 1.9219e-07 - val_loss: 0.0644 - val_mse: 2.1241e-07\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0639 - mse: 1.9244e-07 - val_loss: 0.0633 - val_mse: 2.1317e-07\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0628 - mse: 1.9302e-07 - val_loss: 0.0623 - val_mse: 2.1740e-07\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0617 - mse: 1.9453e-07 - val_loss: 0.0612 - val_mse: 2.1556e-07\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0607 - mse: 1.9485e-07 - val_loss: 0.0602 - val_mse: 2.1778e-07\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 151us/sample - loss: 0.0597 - mse: 1.9550e-07 - val_loss: 0.0591 - val_mse: 2.1673e-07\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0586 - mse: 1.9641e-07 - val_loss: 0.0581 - val_mse: 2.1675e-07\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0576 - mse: 1.9679e-07 - val_loss: 0.0571 - val_mse: 2.1763e-07\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0566 - mse: 1.9788e-07 - val_loss: 0.0561 - val_mse: 2.1886e-07\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0556 - mse: 1.9842e-07 - val_loss: 0.0551 - val_mse: 2.2190e-07\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0546 - mse: 1.9937e-07 - val_loss: 0.0541 - val_mse: 2.2000e-07\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0537 - mse: 2.0014e-07 - val_loss: 0.0532 - val_mse: 2.2195e-07\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0527 - mse: 2.0089e-07 - val_loss: 0.0522 - val_mse: 2.2173e-07\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0518 - mse: 2.0151e-07 - val_loss: 0.0513 - val_mse: 2.2400e-07\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0508 - mse: 2.0222e-07 - val_loss: 0.0504 - val_mse: 2.2295e-07\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0499 - mse: 2.0363e-07 - val_loss: 0.0494 - val_mse: 2.3078e-07\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 175us/sample - loss: 0.0811 - mse: 4.8977e-09 - val_loss: 0.0805 - val_mse: 3.8438e-09\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0798 - mse: 3.9667e-09 - val_loss: 0.0792 - val_mse: 3.4730e-09\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0786 - mse: 3.6930e-09 - val_loss: 0.0780 - val_mse: 3.3361e-09\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0774 - mse: 3.5256e-09 - val_loss: 0.0768 - val_mse: 3.1814e-09\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0762 - mse: 3.4172e-09 - val_loss: 0.0756 - val_mse: 3.1080e-09\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0750 - mse: 3.3364e-09 - val_loss: 0.0744 - val_mse: 3.0598e-09\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0738 - mse: 3.2730e-09 - val_loss: 0.0733 - val_mse: 3.0271e-09\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0727 - mse: 3.2299e-09 - val_loss: 0.0721 - val_mse: 2.9923e-09\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0715 - mse: 3.1981e-09 - val_loss: 0.0709 - val_mse: 3.0108e-09\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0704 - mse: 3.1674e-09 - val_loss: 0.0698 - val_mse: 2.9766e-09\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0692 - mse: 3.1422e-09 - val_loss: 0.0687 - val_mse: 2.9647e-09\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0681 - mse: 3.1215e-09 - val_loss: 0.0676 - val_mse: 2.9327e-09\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0670 - mse: 3.1051e-09 - val_loss: 0.0664 - val_mse: 2.9298e-09\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0659 - mse: 3.0896e-09 - val_loss: 0.0654 - val_mse: 2.9359e-09\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0648 - mse: 3.0743e-09 - val_loss: 0.0643 - val_mse: 2.9161e-09\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0637 - mse: 3.0588e-09 - val_loss: 0.0632 - val_mse: 2.9224e-09\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0627 - mse: 3.0473e-09 - val_loss: 0.0621 - val_mse: 2.9035e-09\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0616 - mse: 3.0321e-09 - val_loss: 0.0611 - val_mse: 2.8930e-09\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0606 - mse: 3.0271e-09 - val_loss: 0.0600 - val_mse: 2.8854e-09\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0595 - mse: 3.0169e-09 - val_loss: 0.0590 - val_mse: 2.8815e-09\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0585 - mse: 3.0034e-09 - val_loss: 0.0580 - val_mse: 2.9038e-09\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0575 - mse: 2.9994e-09 - val_loss: 0.0570 - val_mse: 2.8909e-09\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0565 - mse: 2.9919e-09 - val_loss: 0.0560 - val_mse: 2.8693e-09\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0555 - mse: 2.9814e-09 - val_loss: 0.0550 - val_mse: 2.8887e-09\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0545 - mse: 2.9787e-09 - val_loss: 0.0540 - val_mse: 2.8564e-09\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0536 - mse: 2.9733e-09 - val_loss: 0.0531 - val_mse: 2.8622e-09\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 151us/sample - loss: 0.0526 - mse: 2.9671e-09 - val_loss: 0.0521 - val_mse: 2.8525e-09\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0516 - mse: 2.9635e-09 - val_loss: 0.0512 - val_mse: 2.8637e-09\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 152us/sample - loss: 0.0507 - mse: 2.9575e-09 - val_loss: 0.0502 - val_mse: 2.8439e-09\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0498 - mse: 2.9535e-09 - val_loss: 0.0493 - val_mse: 2.8397e-09\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 176us/sample - loss: 0.0811 - mse: 4.2575e-07 - val_loss: 0.0805 - val_mse: 3.8927e-07\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0799 - mse: 3.9781e-07 - val_loss: 0.0793 - val_mse: 3.8335e-07\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0787 - mse: 3.9272e-07 - val_loss: 0.0781 - val_mse: 3.7637e-07\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0774 - mse: 3.9185e-07 - val_loss: 0.0768 - val_mse: 3.8067e-07\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0762 - mse: 3.9137e-07 - val_loss: 0.0757 - val_mse: 3.7762e-07\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0751 - mse: 3.9282e-07 - val_loss: 0.0745 - val_mse: 3.9038e-07\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0739 - mse: 3.9357e-07 - val_loss: 0.0733 - val_mse: 3.8005e-07\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0727 - mse: 3.9370e-07 - val_loss: 0.0721 - val_mse: 3.9187e-07\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0716 - mse: 3.9638e-07 - val_loss: 0.0710 - val_mse: 3.8459e-07\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0704 - mse: 3.9817e-07 - val_loss: 0.0698 - val_mse: 3.9891e-07\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0693 - mse: 3.9977e-07 - val_loss: 0.0687 - val_mse: 3.9013e-07\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0682 - mse: 4.0113e-07 - val_loss: 0.0676 - val_mse: 3.8910e-07\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0670 - mse: 4.0357e-07 - val_loss: 0.0665 - val_mse: 3.8990e-07\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0659 - mse: 4.0469e-07 - val_loss: 0.0654 - val_mse: 3.9399e-07\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0649 - mse: 4.0679e-07 - val_loss: 0.0643 - val_mse: 3.9334e-07\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0638 - mse: 4.0810e-07 - val_loss: 0.0632 - val_mse: 3.9568e-07\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0627 - mse: 4.0990e-07 - val_loss: 0.0622 - val_mse: 4.0502e-07\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0617 - mse: 4.1189e-07 - val_loss: 0.0611 - val_mse: 4.0084e-07\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0606 - mse: 4.1353e-07 - val_loss: 0.0601 - val_mse: 4.0113e-07\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0596 - mse: 4.1566e-07 - val_loss: 0.0591 - val_mse: 4.0419e-07\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0585 - mse: 4.1655e-07 - val_loss: 0.0580 - val_mse: 4.2364e-07\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0575 - mse: 4.1832e-07 - val_loss: 0.0570 - val_mse: 4.0934e-07\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0565 - mse: 4.2069e-07 - val_loss: 0.0560 - val_mse: 4.0831e-07\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0555 - mse: 4.2284e-07 - val_loss: 0.0551 - val_mse: 4.1151e-07\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0546 - mse: 4.2409e-07 - val_loss: 0.0541 - val_mse: 4.1263e-07\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0536 - mse: 4.2593e-07 - val_loss: 0.0531 - val_mse: 4.1643e-07\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0526 - mse: 4.2789e-07 - val_loss: 0.0522 - val_mse: 4.1488e-07\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0517 - mse: 4.2895e-07 - val_loss: 0.0512 - val_mse: 4.1730e-07\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0508 - mse: 4.3013e-07 - val_loss: 0.0503 - val_mse: 4.2963e-07\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0498 - mse: 4.3153e-07 - val_loss: 0.0494 - val_mse: 4.2776e-07\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 177us/sample - loss: 0.0811 - mse: 5.7491e-07 - val_loss: 0.0805 - val_mse: 5.1066e-07\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0799 - mse: 5.3872e-07 - val_loss: 0.0792 - val_mse: 4.8920e-07\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0786 - mse: 5.2399e-07 - val_loss: 0.0780 - val_mse: 4.7695e-07\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0774 - mse: 5.1455e-07 - val_loss: 0.0768 - val_mse: 4.6885e-07\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0762 - mse: 5.1111e-07 - val_loss: 0.0756 - val_mse: 4.6506e-07\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0750 - mse: 5.0872e-07 - val_loss: 0.0744 - val_mse: 4.7064e-07\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0738 - mse: 5.0870e-07 - val_loss: 0.0733 - val_mse: 4.6729e-07\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0727 - mse: 5.0869e-07 - val_loss: 0.0721 - val_mse: 4.6419e-07\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0715 - mse: 5.0902e-07 - val_loss: 0.0709 - val_mse: 4.6543e-07\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0704 - mse: 5.1059e-07 - val_loss: 0.0698 - val_mse: 4.6648e-07\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0692 - mse: 5.1269e-07 - val_loss: 0.0687 - val_mse: 4.6881e-07\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0681 - mse: 5.1426e-07 - val_loss: 0.0676 - val_mse: 4.6996e-07\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0670 - mse: 5.1636e-07 - val_loss: 0.0664 - val_mse: 4.7765e-07\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0659 - mse: 5.1956e-07 - val_loss: 0.0654 - val_mse: 4.7952e-07\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0648 - mse: 5.2092e-07 - val_loss: 0.0643 - val_mse: 4.9895e-07\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0637 - mse: 5.2273e-07 - val_loss: 0.0632 - val_mse: 4.7958e-07\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0627 - mse: 5.2446e-07 - val_loss: 0.0621 - val_mse: 5.4257e-07\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 150us/sample - loss: 0.0616 - mse: 5.2801e-07 - val_loss: 0.0611 - val_mse: 4.8625e-07\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 151us/sample - loss: 0.0606 - mse: 5.2920e-07 - val_loss: 0.0600 - val_mse: 4.9480e-07\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 162us/sample - loss: 0.0595 - mse: 5.3137e-07 - val_loss: 0.0590 - val_mse: 4.8738e-07\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0585 - mse: 5.3390e-07 - val_loss: 0.0580 - val_mse: 4.8917e-07\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 165us/sample - loss: 0.0575 - mse: 5.3484e-07 - val_loss: 0.0570 - val_mse: 4.9409e-07\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0565 - mse: 5.3825e-07 - val_loss: 0.0560 - val_mse: 4.9372e-07\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0555 - mse: 5.3971e-07 - val_loss: 0.0550 - val_mse: 4.9566e-07\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0545 - mse: 5.4169e-07 - val_loss: 0.0540 - val_mse: 5.2318e-07\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0535 - mse: 5.4444e-07 - val_loss: 0.0531 - val_mse: 5.4385e-07\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0526 - mse: 5.4553e-07 - val_loss: 0.0521 - val_mse: 5.0272e-07\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0516 - mse: 5.4785e-07 - val_loss: 0.0512 - val_mse: 5.0362e-07\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0507 - mse: 5.4986e-07 - val_loss: 0.0502 - val_mse: 5.0770e-07\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0498 - mse: 5.5261e-07 - val_loss: 0.0493 - val_mse: 5.0718e-07\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 175us/sample - loss: 0.0813 - mse: 1.6874e-07 - val_loss: 0.0806 - val_mse: 1.5896e-07\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0800 - mse: 1.5795e-07 - val_loss: 0.0794 - val_mse: 1.5408e-07\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0788 - mse: 1.5396e-07 - val_loss: 0.0782 - val_mse: 1.5158e-07\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0776 - mse: 1.5283e-07 - val_loss: 0.0770 - val_mse: 1.5095e-07\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0764 - mse: 1.5255e-07 - val_loss: 0.0758 - val_mse: 1.5065e-07\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0752 - mse: 1.5241e-07 - val_loss: 0.0746 - val_mse: 1.5095e-07\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0740 - mse: 1.5287e-07 - val_loss: 0.0734 - val_mse: 1.5175e-07\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0728 - mse: 1.5341e-07 - val_loss: 0.0723 - val_mse: 1.5306e-07\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 149us/sample - loss: 0.0717 - mse: 1.5351e-07 - val_loss: 0.0711 - val_mse: 1.5300e-07\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0705 - mse: 1.5385e-07 - val_loss: 0.0700 - val_mse: 1.5228e-07\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0694 - mse: 1.5413e-07 - val_loss: 0.0688 - val_mse: 1.5265e-07\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0683 - mse: 1.5459e-07 - val_loss: 0.0677 - val_mse: 1.5486e-07\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0672 - mse: 1.5532e-07 - val_loss: 0.0666 - val_mse: 1.5672e-07\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0661 - mse: 1.5616e-07 - val_loss: 0.0655 - val_mse: 1.5452e-07\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0650 - mse: 1.5657e-07 - val_loss: 0.0644 - val_mse: 1.5530e-07\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0639 - mse: 1.5734e-07 - val_loss: 0.0633 - val_mse: 1.5587e-07\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0628 - mse: 1.5765e-07 - val_loss: 0.0623 - val_mse: 1.5677e-07\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0618 - mse: 1.5848e-07 - val_loss: 0.0612 - val_mse: 1.6011e-07\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0607 - mse: 1.5933e-07 - val_loss: 0.0602 - val_mse: 1.5782e-07\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0597 - mse: 1.6008e-07 - val_loss: 0.0592 - val_mse: 1.5864e-07\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0586 - mse: 1.6067e-07 - val_loss: 0.0581 - val_mse: 1.5935e-07\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0576 - mse: 1.6134e-07 - val_loss: 0.0571 - val_mse: 1.6257e-07\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0566 - mse: 1.6227e-07 - val_loss: 0.0561 - val_mse: 1.6094e-07\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0556 - mse: 1.6292e-07 - val_loss: 0.0551 - val_mse: 1.6172e-07\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0547 - mse: 1.6370e-07 - val_loss: 0.0542 - val_mse: 1.6558e-07\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0537 - mse: 1.6427e-07 - val_loss: 0.0532 - val_mse: 1.6639e-07\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0527 - mse: 1.6518e-07 - val_loss: 0.0522 - val_mse: 1.6394e-07\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0518 - mse: 1.6603e-07 - val_loss: 0.0513 - val_mse: 1.6495e-07\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0508 - mse: 1.6634e-07 - val_loss: 0.0504 - val_mse: 1.6523e-07\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0499 - mse: 1.6713e-07 - val_loss: 0.0494 - val_mse: 1.6606e-07\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 182us/sample - loss: 0.0813 - mse: 1.4949e-08 - val_loss: 0.0807 - val_mse: 9.5434e-09\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0801 - mse: 1.0557e-08 - val_loss: 0.0794 - val_mse: 8.3234e-09\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0788 - mse: 9.5593e-09 - val_loss: 0.0782 - val_mse: 7.6977e-09\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0776 - mse: 9.0438e-09 - val_loss: 0.0770 - val_mse: 7.5345e-09\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0764 - mse: 8.7435e-09 - val_loss: 0.0758 - val_mse: 7.2561e-09\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0752 - mse: 8.5607e-09 - val_loss: 0.0746 - val_mse: 7.0944e-09\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0740 - mse: 8.4381e-09 - val_loss: 0.0735 - val_mse: 7.0261e-09\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0729 - mse: 8.3551e-09 - val_loss: 0.0723 - val_mse: 7.0993e-09\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0717 - mse: 8.3133e-09 - val_loss: 0.0711 - val_mse: 6.9585e-09\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0706 - mse: 8.2954e-09 - val_loss: 0.0700 - val_mse: 6.9373e-09\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0694 - mse: 8.2601e-09 - val_loss: 0.0689 - val_mse: 6.9283e-09\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0683 - mse: 8.2336e-09 - val_loss: 0.0678 - val_mse: 6.9787e-09\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0672 - mse: 8.2334e-09 - val_loss: 0.0666 - val_mse: 6.9072e-09\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0661 - mse: 8.2179e-09 - val_loss: 0.0655 - val_mse: 6.9326e-09\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0650 - mse: 8.2177e-09 - val_loss: 0.0645 - val_mse: 6.9166e-09\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0639 - mse: 8.2235e-09 - val_loss: 0.0634 - val_mse: 6.9162e-09\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0629 - mse: 8.2407e-09 - val_loss: 0.0623 - val_mse: 6.9142e-09\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 154us/sample - loss: 0.0618 - mse: 8.2243e-09 - val_loss: 0.0613 - val_mse: 6.9143e-09\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0608 - mse: 8.2450e-09 - val_loss: 0.0602 - val_mse: 6.9386e-09\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 150us/sample - loss: 0.0597 - mse: 8.2579e-09 - val_loss: 0.0592 - val_mse: 7.0121e-09\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0587 - mse: 8.2823e-09 - val_loss: 0.0582 - val_mse: 7.2201e-09\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0577 - mse: 8.3191e-09 - val_loss: 0.0572 - val_mse: 7.0793e-09\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0567 - mse: 8.3470e-09 - val_loss: 0.0562 - val_mse: 7.0330e-09\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0557 - mse: 8.3771e-09 - val_loss: 0.0552 - val_mse: 7.0928e-09\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0547 - mse: 8.3956e-09 - val_loss: 0.0542 - val_mse: 7.0687e-09\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0537 - mse: 8.4184e-09 - val_loss: 0.0533 - val_mse: 7.1008e-09\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0528 - mse: 8.4697e-09 - val_loss: 0.0523 - val_mse: 7.2260e-09\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0518 - mse: 8.5344e-09 - val_loss: 0.0514 - val_mse: 7.1874e-09\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0509 - mse: 8.6005e-09 - val_loss: 0.0504 - val_mse: 7.2589e-09\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0500 - mse: 8.6500e-09 - val_loss: 0.0495 - val_mse: 7.3105e-09\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 180us/sample - loss: 0.0810 - mse: 1.6919e-08 - val_loss: 0.0804 - val_mse: 1.5749e-08\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0798 - mse: 1.5614e-08 - val_loss: 0.0792 - val_mse: 1.5152e-08\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0786 - mse: 1.5072e-08 - val_loss: 0.0779 - val_mse: 1.4974e-08\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0773 - mse: 1.4759e-08 - val_loss: 0.0767 - val_mse: 1.4794e-08\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0761 - mse: 1.4525e-08 - val_loss: 0.0755 - val_mse: 1.4304e-08\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0749 - mse: 1.4300e-08 - val_loss: 0.0744 - val_mse: 1.4141e-08\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0738 - mse: 1.4134e-08 - val_loss: 0.0732 - val_mse: 1.3976e-08\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0726 - mse: 1.3990e-08 - val_loss: 0.0720 - val_mse: 1.3894e-08\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0714 - mse: 1.3906e-08 - val_loss: 0.0709 - val_mse: 1.3801e-08\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0703 - mse: 1.3834e-08 - val_loss: 0.0697 - val_mse: 1.3746e-08\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0692 - mse: 1.3767e-08 - val_loss: 0.0686 - val_mse: 1.3644e-08\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0680 - mse: 1.3656e-08 - val_loss: 0.0675 - val_mse: 1.3620e-08\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0669 - mse: 1.3596e-08 - val_loss: 0.0664 - val_mse: 1.3528e-08\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0658 - mse: 1.3556e-08 - val_loss: 0.0653 - val_mse: 1.3534e-08\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 149us/sample - loss: 0.0647 - mse: 1.3512e-08 - val_loss: 0.0642 - val_mse: 1.3449e-08\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0637 - mse: 1.3499e-08 - val_loss: 0.0631 - val_mse: 1.3423e-08\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0626 - mse: 1.3471e-08 - val_loss: 0.0621 - val_mse: 1.3447e-08\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0615 - mse: 1.3460e-08 - val_loss: 0.0610 - val_mse: 1.3446e-08\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0605 - mse: 1.3451e-08 - val_loss: 0.0600 - val_mse: 1.3587e-08\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0594 - mse: 1.3452e-08 - val_loss: 0.0589 - val_mse: 1.3389e-08\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0584 - mse: 1.3470e-08 - val_loss: 0.0579 - val_mse: 1.3383e-08\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0574 - mse: 1.3509e-08 - val_loss: 0.0569 - val_mse: 1.3401e-08\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0564 - mse: 1.3519e-08 - val_loss: 0.0559 - val_mse: 1.3627e-08\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0554 - mse: 1.3534e-08 - val_loss: 0.0549 - val_mse: 1.3384e-08\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0544 - mse: 1.3557e-08 - val_loss: 0.0539 - val_mse: 1.3473e-08\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0535 - mse: 1.3576e-08 - val_loss: 0.0530 - val_mse: 1.3586e-08\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0525 - mse: 1.3609e-08 - val_loss: 0.0520 - val_mse: 1.3585e-08\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0516 - mse: 1.3648e-08 - val_loss: 0.0511 - val_mse: 1.3455e-08\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 144us/sample - loss: 0.0506 - mse: 1.3697e-08 - val_loss: 0.0502 - val_mse: 1.3475e-08\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0497 - mse: 1.3723e-08 - val_loss: 0.0492 - val_mse: 1.3495e-08\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 178us/sample - loss: 0.0810 - mse: 1.0382e-08 - val_loss: 0.0804 - val_mse: 9.8259e-09\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0798 - mse: 9.0077e-09 - val_loss: 0.0792 - val_mse: 9.0163e-09\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0786 - mse: 8.4798e-09 - val_loss: 0.0780 - val_mse: 8.6631e-09\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0774 - mse: 8.2158e-09 - val_loss: 0.0768 - val_mse: 8.5528e-09\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0762 - mse: 8.0109e-09 - val_loss: 0.0756 - val_mse: 8.4183e-09\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0750 - mse: 7.8679e-09 - val_loss: 0.0744 - val_mse: 8.2171e-09\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0738 - mse: 7.7503e-09 - val_loss: 0.0732 - val_mse: 8.1699e-09\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0726 - mse: 7.6807e-09 - val_loss: 0.0721 - val_mse: 8.0790e-09\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0715 - mse: 7.6204e-09 - val_loss: 0.0709 - val_mse: 8.0369e-09\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0703 - mse: 7.5522e-09 - val_loss: 0.0698 - val_mse: 8.0051e-09\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0692 - mse: 7.5086e-09 - val_loss: 0.0686 - val_mse: 7.9700e-09\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 162us/sample - loss: 0.0681 - mse: 7.4826e-09 - val_loss: 0.0675 - val_mse: 8.0217e-09\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0670 - mse: 7.4506e-09 - val_loss: 0.0664 - val_mse: 7.9562e-09\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 164us/sample - loss: 0.0659 - mse: 7.4297e-09 - val_loss: 0.0653 - val_mse: 7.9534e-09\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 157us/sample - loss: 0.0648 - mse: 7.4119e-09 - val_loss: 0.0642 - val_mse: 7.9256e-09\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0637 - mse: 7.4122e-09 - val_loss: 0.0631 - val_mse: 8.0821e-09\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0626 - mse: 7.4052e-09 - val_loss: 0.0621 - val_mse: 8.0229e-09\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0616 - mse: 7.4117e-09 - val_loss: 0.0610 - val_mse: 7.9272e-09\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0605 - mse: 7.4017e-09 - val_loss: 0.0600 - val_mse: 7.9174e-09\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0595 - mse: 7.3960e-09 - val_loss: 0.0590 - val_mse: 7.9315e-09\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0585 - mse: 7.3936e-09 - val_loss: 0.0579 - val_mse: 8.1896e-09\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0574 - mse: 7.4037e-09 - val_loss: 0.0569 - val_mse: 7.9465e-09\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0564 - mse: 7.4136e-09 - val_loss: 0.0559 - val_mse: 8.0406e-09\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0555 - mse: 7.4229e-09 - val_loss: 0.0550 - val_mse: 8.0449e-09\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0545 - mse: 7.4356e-09 - val_loss: 0.0540 - val_mse: 8.0063e-09\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0535 - mse: 7.4635e-09 - val_loss: 0.0530 - val_mse: 8.0225e-09\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0525 - mse: 7.4795e-09 - val_loss: 0.0521 - val_mse: 8.1086e-09\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 152us/sample - loss: 0.0516 - mse: 7.4984e-09 - val_loss: 0.0511 - val_mse: 8.0628e-09\n",
      "Epoch 29/30\n",
      "18542/18542 [==============================] - 3s 148us/sample - loss: 0.0507 - mse: 7.5301e-09 - val_loss: 0.0502 - val_mse: 8.1008e-09\n",
      "Epoch 30/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0497 - mse: 7.5564e-09 - val_loss: 0.0493 - val_mse: 8.1226e-09\n",
      "Train on 18542 samples, validate on 4636 samples\n",
      "Epoch 1/30\n",
      "18542/18542 [==============================] - 3s 177us/sample - loss: 0.0812 - mse: 5.8598e-07 - val_loss: 0.0806 - val_mse: 5.4287e-07\n",
      "Epoch 2/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0800 - mse: 5.3052e-07 - val_loss: 0.0794 - val_mse: 5.3996e-07\n",
      "Epoch 3/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0788 - mse: 5.2568e-07 - val_loss: 0.0782 - val_mse: 5.2872e-07\n",
      "Epoch 4/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0776 - mse: 5.2662e-07 - val_loss: 0.0770 - val_mse: 5.3185e-07\n",
      "Epoch 5/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0764 - mse: 5.2677e-07 - val_loss: 0.0758 - val_mse: 5.3911e-07\n",
      "Epoch 6/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0752 - mse: 5.2969e-07 - val_loss: 0.0746 - val_mse: 5.4398e-07\n",
      "Epoch 7/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0740 - mse: 5.2850e-07 - val_loss: 0.0734 - val_mse: 5.5824e-07\n",
      "Epoch 8/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0728 - mse: 5.3243e-07 - val_loss: 0.0722 - val_mse: 5.4453e-07\n",
      "Epoch 9/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0717 - mse: 5.3426e-07 - val_loss: 0.0711 - val_mse: 5.3979e-07\n",
      "Epoch 10/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0705 - mse: 5.3925e-07 - val_loss: 0.0699 - val_mse: 5.4241e-07\n",
      "Epoch 11/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0694 - mse: 5.4203e-07 - val_loss: 0.0688 - val_mse: 5.4792e-07\n",
      "Epoch 12/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0683 - mse: 5.4559e-07 - val_loss: 0.0677 - val_mse: 5.5103e-07\n",
      "Epoch 13/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0671 - mse: 5.4924e-07 - val_loss: 0.0666 - val_mse: 5.9032e-07\n",
      "Epoch 14/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0660 - mse: 5.5442e-07 - val_loss: 0.0655 - val_mse: 5.5888e-07\n",
      "Epoch 15/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0649 - mse: 5.5772e-07 - val_loss: 0.0644 - val_mse: 5.6730e-07\n",
      "Epoch 16/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0639 - mse: 5.6118e-07 - val_loss: 0.0633 - val_mse: 5.7214e-07\n",
      "Epoch 17/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0628 - mse: 5.6536e-07 - val_loss: 0.0623 - val_mse: 5.7140e-07\n",
      "Epoch 18/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0617 - mse: 5.6876e-07 - val_loss: 0.0612 - val_mse: 5.7273e-07\n",
      "Epoch 19/30\n",
      "18542/18542 [==============================] - 3s 147us/sample - loss: 0.0607 - mse: 5.7252e-07 - val_loss: 0.0602 - val_mse: 5.7786e-07\n",
      "Epoch 20/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0597 - mse: 5.7671e-07 - val_loss: 0.0591 - val_mse: 5.7995e-07\n",
      "Epoch 21/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0586 - mse: 5.8063e-07 - val_loss: 0.0581 - val_mse: 5.8894e-07\n",
      "Epoch 22/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0576 - mse: 5.8368e-07 - val_loss: 0.0571 - val_mse: 5.8716e-07\n",
      "Epoch 23/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0566 - mse: 5.8742e-07 - val_loss: 0.0561 - val_mse: 6.0675e-07\n",
      "Epoch 24/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0556 - mse: 5.9276e-07 - val_loss: 0.0551 - val_mse: 6.0849e-07\n",
      "Epoch 25/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0546 - mse: 5.9561e-07 - val_loss: 0.0541 - val_mse: 6.0886e-07\n",
      "Epoch 26/30\n",
      "18542/18542 [==============================] - 3s 145us/sample - loss: 0.0537 - mse: 5.9934e-07 - val_loss: 0.0532 - val_mse: 6.1342e-07\n",
      "Epoch 27/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0527 - mse: 6.0363e-07 - val_loss: 0.0522 - val_mse: 6.0755e-07\n",
      "Epoch 28/30\n",
      "18542/18542 [==============================] - 3s 146us/sample - loss: 0.0518 - mse: 6.0804e-07 - val_loss: 0.0513 - val_mse: 6.1023e-07\n",
      "Epoch 29/30\n",
      "14720/18542 [======================>.......] - ETA: 0s - loss: 0.0509 - mse: 6.0791e-07"
     ]
    }
   ],
   "source": [
    "VAL_LOSE_OPTIMAL_RAND = []\n",
    "VAL_MSE_OPTIMAL_RAND = []\n",
    "for i in range(output_train.shape[1]): \n",
    "    temp = DNN_train(output_train[:, i], output_test[:, i])\n",
    "    VAL_MSE_OPTIMAL_RAND.append(temp[0])\n",
    "    VAL_LOSE_OPTIMAL_RAND.append(temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('val_mse_optimal_rand.txt', VAL_MSE_OPTIMAL_RAND)\n",
    "np.savetxt('val_loss_optimal_rand.txt', VAL_LOSE_OPTIMAL_RAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, color='blue', label='Train')\n",
    "    plt.plot(epochs, val_acc, color='orange', label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    _ = plt.figure()\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, color='blue', label='Train')\n",
    "    plt.plot(epochs, val_loss, color='orange', label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
