{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "HOME = '../load_data/'\n",
    "\n",
    "INPUT_TRAIN = '{}input_train.csv'.format(HOME)\n",
    "INPUT_TEST = '{}input_test.csv'.format(HOME)\n",
    "OUTPUT_TRAIN = '{}output_train-1.csv'.format(HOME)\n",
    "OUTPUT_TEST = '{}output_test-1.csv'.format(HOME)\n",
    "OUTPUT_GENES = '{}output_genes-1.txt'.format(HOME)\n",
    "\n",
    "MSE_OUTPUT = '37x37_pearson_mse.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframes\n",
    "train_input = pd.read_csv(INPUT_TRAIN, header=0, index_col=0)\n",
    "train_output = pd.read_csv(OUTPUT_TRAIN, header=0, index_col=0)\n",
    "test_input = pd.read_csv(INPUT_TEST, header=0, index_col=0)\n",
    "test_output = pd.read_csv(OUTPUT_TEST, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37x37 input, TFs chosen based on Pearson correlation to output genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 37^2 most correlated transcription factors for each output gene\n",
    "# reshape input dataframe into 37*37*1 arrays\n",
    "input_df = pd.concat([train_input, test_input], axis=0)\n",
    "output_df = pd.concat([train_output, test_output], axis=0)\n",
    "cor_input_train = dict()\n",
    "cor_input_test = dict()\n",
    "for gene in test_output.columns:\n",
    "    cor = input_df.corrwith(output_df[gene])\n",
    "    tfs = cor.nlargest(37**2).index\n",
    "    cor_input_train[gene] = train_input[tfs].to_numpy().reshape(18542, 37, 37, 1)\n",
    "    cor_input_test[gene] = test_input[tfs].to_numpy().reshape(4636, 37, 37, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 3.4728e-06 - mse: 3.4728e-06 - val_loss: 1.9376e-07 - val_mse: 1.9376e-07\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.9451e-07 - mse: 3.9451e-07 - val_loss: 1.7575e-07 - val_mse: 1.7575e-07\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.4634e-07 - mse: 3.4634e-07 - val_loss: 3.4701e-07 - val_mse: 3.4701e-07\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.9596e-07 - mse: 2.9596e-07 - val_loss: 1.9159e-07 - val_mse: 1.9159e-07\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.0146e-07 - mse: 3.0146e-07 - val_loss: 2.2687e-07 - val_mse: 2.2687e-07\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.0158e-07 - mse: 3.0158e-07 - val_loss: 6.1904e-07 - val_mse: 6.1904e-07\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.7900e-07 - mse: 2.7900e-07 - val_loss: 3.4580e-07 - val_mse: 3.4580e-07\n",
      "4636/4636 [==============================] - 2s 468us/sample - loss: 2.8114e-07 - mse: 2.8114e-07\n",
      "Apoe\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 9.2182e-06 - mse: 9.2182e-06 - val_loss: 1.8140e-05 - val_mse: 1.8140e-05\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 7.4983e-06 - mse: 7.4983e-06 - val_loss: 1.9255e-05 - val_mse: 1.9255e-05\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.8196e-06 - mse: 6.8195e-06 - val_loss: 1.8700e-05 - val_mse: 1.8700e-05\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.6775e-06 - mse: 6.6775e-06 - val_loss: 1.9751e-05 - val_mse: 1.9751e-05\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.7088e-06 - mse: 6.7088e-06 - val_loss: 1.9415e-05 - val_mse: 1.9415e-05\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.6296e-06 - mse: 6.6296e-06 - val_loss: 2.1122e-05 - val_mse: 2.1122e-05\n",
      "4636/4636 [==============================] - 2s 439us/sample - loss: 9.9311e-06 - mse: 9.9311e-06\n",
      "Gusb\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 7.6781e-07 - mse: 7.6781e-07 - val_loss: 2.4297e-08 - val_mse: 2.4297e-08\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.7506e-08 - mse: 5.7506e-08 - val_loss: 9.3342e-09 - val_mse: 9.3342e-09\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.3646e-07 - mse: 3.3646e-07 - val_loss: 1.1246e-08 - val_mse: 1.1246e-08\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.7111e-09 - mse: 4.7111e-09 - val_loss: 1.2452e-08 - val_mse: 1.2452e-08\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 9.9377e-09 - mse: 9.9377e-09 - val_loss: 8.1778e-09 - val_mse: 8.1778e-09\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.5360e-08 - mse: 1.5360e-08 - val_loss: 6.0264e-08 - val_mse: 6.0264e-08\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.1691e-08 - mse: 3.1691e-08 - val_loss: 5.6627e-08 - val_mse: 5.6627e-08\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.0558e-08 - mse: 1.0558e-08 - val_loss: 4.2976e-08 - val_mse: 4.2976e-08\n",
      "Epoch 9/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.7529e-08 - mse: 1.7529e-08 - val_loss: 3.6417e-08 - val_mse: 3.6417e-08\n",
      "Epoch 10/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.3450e-08 - mse: 1.3450e-08 - val_loss: 2.4728e-08 - val_mse: 2.4728e-08\n",
      "4636/4636 [==============================] - 2s 449us/sample - loss: 2.1212e-08 - mse: 2.1212e-08\n",
      "Lamp5\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 2.8177e-06 - mse: 2.8177e-06 - val_loss: 5.1278e-07 - val_mse: 5.1278e-07\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 7.3443e-07 - mse: 7.3443e-07 - val_loss: 1.7345e-06 - val_mse: 1.7345e-06\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 7.3092e-07 - mse: 7.3092e-07 - val_loss: 1.1917e-06 - val_mse: 1.1917e-06\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.0060e-07 - mse: 6.0060e-07 - val_loss: 5.1510e-07 - val_mse: 5.1510e-07\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.0381e-07 - mse: 6.0381e-07 - val_loss: 5.7452e-07 - val_mse: 5.7452e-07\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.5575e-07 - mse: 5.5575e-07 - val_loss: 5.3783e-07 - val_mse: 5.3783e-07\n",
      "4636/4636 [==============================] - 2s 447us/sample - loss: 5.0764e-07 - mse: 5.0764e-07\n",
      "Mbp\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 1.6524e-06 - mse: 1.6524e-06 - val_loss: 2.4391e-06 - val_mse: 2.4391e-06\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.3826e-07 - mse: 6.3826e-07 - val_loss: 1.3000e-06 - val_mse: 1.3000e-06\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.5534e-07 - mse: 5.5534e-07 - val_loss: 1.3151e-06 - val_mse: 1.3151e-06\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.2898e-07 - mse: 5.2898e-07 - val_loss: 1.6372e-06 - val_mse: 1.6372e-06\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.6558e-07 - mse: 5.6558e-07 - val_loss: 1.3229e-06 - val_mse: 1.3229e-06\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.9322e-07 - mse: 4.9322e-07 - val_loss: 1.3036e-06 - val_mse: 1.3036e-06\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.8260e-07 - mse: 4.8260e-07 - val_loss: 1.5444e-06 - val_mse: 1.5444e-06\n",
      "4636/4636 [==============================] - 2s 449us/sample - loss: 7.3201e-07 - mse: 7.3201e-07\n",
      "Pvalb\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 1.2969e-06 - mse: 1.2969e-06 - val_loss: 4.0726e-07 - val_mse: 4.0726e-07\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.5365e-07 - mse: 2.5365e-07 - val_loss: 4.4549e-07 - val_mse: 4.4549e-07\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.2948e-07 - mse: 2.2948e-07 - val_loss: 4.5874e-07 - val_mse: 4.5874e-07\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.2682e-07 - mse: 2.2682e-07 - val_loss: 4.2274e-07 - val_mse: 4.2274e-07\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.0888e-07 - mse: 2.0888e-07 - val_loss: 4.0303e-07 - val_mse: 4.0303e-07\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.8049e-07 - mse: 1.8049e-07 - val_loss: 4.0217e-07 - val_mse: 4.0217e-07\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.6370e-07 - mse: 1.6370e-07 - val_loss: 4.0160e-07 - val_mse: 4.0160e-07\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.7337e-07 - mse: 1.7337e-07 - val_loss: 4.0331e-07 - val_mse: 4.0331e-07\n",
      "Epoch 9/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.6365e-07 - mse: 1.6365e-07 - val_loss: 4.0357e-07 - val_mse: 4.0357e-07\n",
      "Epoch 10/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.5704e-07 - mse: 1.5704e-07 - val_loss: 4.0294e-07 - val_mse: 4.0294e-07\n",
      "Epoch 11/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.5837e-07 - mse: 1.5837e-07 - val_loss: 4.0237e-07 - val_mse: 4.0237e-07\n",
      "Epoch 12/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.5629e-07 - mse: 1.5629e-07 - val_loss: 4.2010e-07 - val_mse: 4.2010e-07\n",
      "4636/4636 [==============================] - 2s 450us/sample - loss: 2.0036e-07 - mse: 2.0036e-07\n",
      "Rorb\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 1.1724e-06 - mse: 1.1724e-06 - val_loss: 2.0023e-07 - val_mse: 2.0023e-07\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 9.4904e-08 - mse: 9.4904e-08 - val_loss: 2.3127e-08 - val_mse: 2.3127e-08\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 6.4192e-08 - mse: 6.4192e-08 - val_loss: 1.3862e-08 - val_mse: 1.3862e-08\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.1410e-08 - mse: 5.1410e-08 - val_loss: 3.4323e-08 - val_mse: 3.4323e-08\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.4075e-08 - mse: 4.4075e-08 - val_loss: 5.1640e-08 - val_mse: 5.1640e-08\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.5636e-08 - mse: 5.5636e-08 - val_loss: 1.9911e-08 - val_mse: 1.9911e-08\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.0232e-07 - mse: 1.0232e-07 - val_loss: 2.7706e-08 - val_mse: 2.7706e-08\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.7313e-08 - mse: 2.7313e-08 - val_loss: 1.8481e-07 - val_mse: 1.8481e-07\n",
      "4636/4636 [==============================] - 2s 452us/sample - loss: 1.9169e-07 - mse: 1.9169e-07\n",
      "S100b\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 7.8106e-07 - mse: 7.8106e-07 - val_loss: 7.0740e-08 - val_mse: 7.0740e-08\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.4584e-08 - mse: 5.4584e-08 - val_loss: 2.1396e-07 - val_mse: 2.1396e-07\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 5.3362e-08 - mse: 5.3362e-08 - val_loss: 6.0136e-08 - val_mse: 6.0136e-08\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 9.0612e-08 - mse: 9.0612e-08 - val_loss: 8.5500e-08 - val_mse: 8.5500e-08\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.3695e-08 - mse: 1.3695e-08 - val_loss: 5.6146e-08 - val_mse: 5.6146e-08\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.9807e-08 - mse: 1.9807e-08 - val_loss: 2.5109e-07 - val_mse: 2.5109e-07\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.1660e-08 - mse: 2.1660e-08 - val_loss: 5.5946e-08 - val_mse: 5.5946e-08\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.7086e-08 - mse: 1.7086e-08 - val_loss: 5.5681e-08 - val_mse: 5.5681e-08\n",
      "Epoch 9/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.6972e-08 - mse: 1.6972e-08 - val_loss: 9.7142e-08 - val_mse: 9.7142e-08\n",
      "Epoch 10/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.7009e-08 - mse: 1.7009e-08 - val_loss: 5.7441e-08 - val_mse: 5.7441e-08\n",
      "Epoch 11/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.5179e-08 - mse: 1.5179e-08 - val_loss: 6.9454e-08 - val_mse: 6.9454e-08\n",
      "Epoch 12/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.3322e-08 - mse: 1.3322e-08 - val_loss: 7.0239e-08 - val_mse: 7.0239e-08\n",
      "Epoch 13/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.4979e-08 - mse: 1.4979e-08 - val_loss: 5.8728e-08 - val_mse: 5.8728e-08\n",
      "4636/4636 [==============================] - 2s 446us/sample - loss: 1.6934e-08 - mse: 1.6934e-08\n",
      "Slc30a3\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 1.0856e-06 - mse: 1.0856e-06 - val_loss: 1.3269e-08 - val_mse: 1.3269e-08\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 7.6283e-08 - mse: 7.6283e-08 - val_loss: 1.0760e-07 - val_mse: 1.0760e-07\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.9884e-08 - mse: 4.9884e-08 - val_loss: 1.2822e-07 - val_mse: 1.2822e-07\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 4.0168e-08 - mse: 4.0168e-08 - val_loss: 7.9648e-09 - val_mse: 7.9648e-09\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.7756e-08 - mse: 8.7756e-08 - val_loss: 2.9391e-08 - val_mse: 2.9391e-08\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.7903e-08 - mse: 3.7903e-08 - val_loss: 2.5109e-08 - val_mse: 2.5109e-08\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 2.6959e-08 - mse: 2.6959e-08 - val_loss: 4.0048e-08 - val_mse: 4.0048e-08\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.1559e-08 - mse: 3.1559e-08 - val_loss: 1.2093e-08 - val_mse: 1.2093e-08\n",
      "Epoch 9/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 3.1253e-08 - mse: 3.1253e-08 - val_loss: 1.2234e-08 - val_mse: 1.2234e-08\n",
      "4636/4636 [==============================] - 2s 446us/sample - loss: 1.3343e-08 - mse: 1.3343e-08\n",
      "Snca\n",
      "Train on 14833 samples, validate on 3709 samples\n",
      "Epoch 1/50\n",
      "14833/14833 [==============================] - 28s 2ms/sample - loss: 3.9495e-06 - mse: 3.9495e-06 - val_loss: 2.0047e-06 - val_mse: 2.0047e-06\n",
      "Epoch 2/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 1.0599e-06 - mse: 1.0599e-06 - val_loss: 9.4138e-07 - val_mse: 9.4138e-07\n",
      "Epoch 3/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 9.2543e-07 - mse: 9.2543e-07 - val_loss: 9.1635e-07 - val_mse: 9.1635e-07\n",
      "Epoch 4/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 9.3959e-07 - mse: 9.3959e-07 - val_loss: 8.0145e-07 - val_mse: 8.0145e-07\n",
      "Epoch 5/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.9079e-07 - mse: 8.9079e-07 - val_loss: 7.8724e-07 - val_mse: 7.8724e-07\n",
      "Epoch 6/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.5084e-07 - mse: 8.5084e-07 - val_loss: 8.9739e-07 - val_mse: 8.9739e-07\n",
      "Epoch 7/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.2712e-07 - mse: 8.2712e-07 - val_loss: 9.6291e-07 - val_mse: 9.6291e-07\n",
      "Epoch 8/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.2685e-07 - mse: 8.2685e-07 - val_loss: 7.7480e-07 - val_mse: 7.7480e-07\n",
      "Epoch 9/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.1561e-07 - mse: 8.1561e-07 - val_loss: 8.5623e-07 - val_mse: 8.5623e-07\n",
      "Epoch 10/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.0896e-07 - mse: 8.0896e-07 - val_loss: 7.9841e-07 - val_mse: 7.9841e-07\n",
      "Epoch 11/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.1180e-07 - mse: 8.1180e-07 - val_loss: 8.5131e-07 - val_mse: 8.5131e-07\n",
      "Epoch 12/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.1691e-07 - mse: 8.1691e-07 - val_loss: 7.9232e-07 - val_mse: 7.9232e-07\n",
      "Epoch 13/50\n",
      "14833/14833 [==============================] - 27s 2ms/sample - loss: 8.1624e-07 - mse: 8.1624e-07 - val_loss: 8.4778e-07 - val_mse: 8.4778e-07\n",
      "4636/4636 [==============================] - 2s 447us/sample - loss: 7.8708e-07 - mse: 7.8708e-07\n",
      "Map\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dbbcba72c994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcor_input_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Map'"
     ]
    }
   ],
   "source": [
    "# train VGG16 model for each gene\n",
    "metrics = dict()\n",
    "\n",
    "for gene in genes:\n",
    "    print(gene)\n",
    "    # model\n",
    "    model = VGG16(include_top=False, weights=None, input_shape=(37,37,1))\n",
    "    x = Flatten()(model.output)\n",
    "    x = Dense(units=4096, activation='relu')(x)\n",
    "    x = Dense(units=4096, activation='relu')(x)\n",
    "    x = Dense(units=1)(x)\n",
    "    model = Model(inputs=model.inputs, outputs=x)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    # training\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model.fit(x=cor_input_train[gene], y=train_output[gene], epochs=50, callbacks=[early_stop], validation_split=.2)\n",
    "\n",
    "    # evaluation\n",
    "    metrics[gene] = (model.evaluate(x=cor_input_test[gene], y=test_output[gene])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'App': 2.8114254574811375e-07,\n",
       " 'Apoe': 9.93106450449807e-06,\n",
       " 'Gusb': 2.121164140815287e-08,\n",
       " 'Lamp5': 5.076448983412173e-07,\n",
       " 'Mbp': 7.320084201043031e-07,\n",
       " 'Pvalb': 2.0035805047576416e-07,\n",
       " 'Rorb': 1.9169013785054322e-07,\n",
       " 'S100b': 1.6933947452792726e-08,\n",
       " 'Slc30a3': 1.3342836044360167e-08,\n",
       " 'Snca': 7.870812282032773e-07}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write mse to csv\n",
    "with open(MSE_OUTPUT, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(metrics.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
